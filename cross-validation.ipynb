{"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"First we read the data","metadata":{"_cell_guid":"334b229d-db29-4cd0-a268-245f0192b828","_uuid":"93d63228dffcde1e1b8305eb71b000257700339d"}},{"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv('../input/melb_data.csv')\ncols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']\nX = data[cols_to_use]\ny = data.Price","metadata":{"_cell_guid":"8219a83e-fb0e-4d4f-b10f-6dd4c823c688","_uuid":"d6b611418224f51efad9e90b6aeb4c137ed583fd","execution":{"iopub.status.busy":"2023-11-06T09:53:50.930372Z","iopub.execute_input":"2023-11-06T09:53:50.931227Z","iopub.status.idle":"2023-11-06T09:53:52.015808Z","shell.execute_reply.started":"2023-11-06T09:53:50.931144Z","shell.execute_reply":"2023-11-06T09:53:52.014972Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Then specify a pipeline of our modeling steps (It can be very difficult to do cross-validation properly if you arent't using [pipelines](https://www.kaggle.com/dansbecker/pipelines))","metadata":{"_cell_guid":"f242f6a8-0094-460d-a43e-6c4183d2d009","_uuid":"5f71fcb8838edb64b1c05e801a2982bbae72318c"}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Imputer\nmy_pipeline = make_pipeline(Imputer(), RandomForestRegressor())","metadata":{"_cell_guid":"76d229a3-9694-4660-be97-3280f77a705b","_uuid":"bab6d2376cf5952a679c2d6d75438fccf9108358","execution":{"iopub.status.busy":"2023-11-06T09:53:52.017114Z","iopub.execute_input":"2023-11-06T09:53:52.017399Z","iopub.status.idle":"2023-11-06T09:53:52.908588Z","shell.execute_reply.started":"2023-11-06T09:53:52.017350Z","shell.execute_reply":"2023-11-06T09:53:52.907872Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Finally get the cross-validation scores:","metadata":{"_cell_guid":"fd20ef5a-8966-40a4-9da9-08dc399b6db8","_uuid":"deffe7bce9a59cbb3ab5966a6532e424ea45755c"}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(my_pipeline, X, y, scoring='neg_mean_absolute_error')\nprint(scores)","metadata":{"_cell_guid":"7d7b7adc-8dad-4274-af1c-58460f7a360d","_uuid":"e75a6151e651b4905453868bacaf6a645ddf13bc","execution":{"iopub.status.busy":"2023-11-06T09:53:52.909715Z","iopub.execute_input":"2023-11-06T09:53:52.909988Z","iopub.status.idle":"2023-11-06T09:53:53.727775Z","shell.execute_reply.started":"2023-11-06T09:53:52.909943Z","shell.execute_reply":"2023-11-06T09:53:53.726800Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[-312633.79946035 -300616.9300481  -299723.34101318]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"You may notice that we specified an argument for *scoring*.  This specifies what measure of model quality to report.  The docs for scikit-learn show a [list of options](http://scikit-learn.org/stable/modules/model_evaluation.html).  \n\nIt is a little surprising that we specify *negative* mean absolute error in this case. Scikit-learn has a convention where all metrics are defined so a high number is better.  Using negatives here allows them to be consistent with that convention, though negative MAE is almost unheard of elsewhere.\n\nYou typically want a single measure of model quality to compare between models.  So we take the average across experiments.","metadata":{"_cell_guid":"f2fdf1b3-7924-4540-8fe6-422e76bcefe4","_uuid":"4c9b1e96b042daf641c9b7412a7d37bd9999ca6f"}},{"cell_type":"code","source":"print('Mean Absolute Error %2f' %(-1 * scores.mean()))","metadata":{"_cell_guid":"2a6bf248-acea-4362-b049-de8086444030","_uuid":"25c2ea179d38a44906607707e82ba999fca52a91","execution":{"iopub.status.busy":"2023-11-06T09:53:53.728966Z","iopub.execute_input":"2023-11-06T09:53:53.729228Z","iopub.status.idle":"2023-11-06T09:53:53.735173Z","shell.execute_reply.started":"2023-11-06T09:53:53.729183Z","shell.execute_reply":"2023-11-06T09:53:53.734265Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Mean Absolute Error 304324.690174\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Conclusion\n\nUsing cross-validation gave us much better measures of model quality, with the added benefit of cleaning up our code (no longer needing to keep track of separate train and test sets.  So, it's a good win.\n\n# Your Turn\n1. Convert the code for your on-going project over from train-test split to cross-validation.  Make sure to remove all code that divides your dataset into training and testing datasets.  Leaving code you don't need any more would be sloppy.\n\n2. Add or remove a predictor from your models.  See the cross-validation score using both sets of predictors, and see how you can compare the scores.","metadata":{"_cell_guid":"edeef0ab-c554-42fe-a707-b6b50dfcc098","_uuid":"9db4ec132f5096b940a8f65f2fd259d1cca3b183"}}]}